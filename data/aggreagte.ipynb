{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import polars as pl\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('processed/city_sec_wage/*.csv')\n",
    "\n",
    "wage = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    year = int(os.path.basename(file)[-8:-4])\n",
    "    current = pd.read_csv(file)\n",
    "    current['city_total'] = current.iloc[:, 1:].sum(axis=1)\n",
    "    current = current.melt(id_vars=['MET2013'], var_name='Sector', value_name='Wage')\n",
    "    current['Year'] = year\n",
    "    wage = pd.concat([wage, current], ignore_index=True)\n",
    "\n",
    "wage.to_csv('aggregate/city_sector_wage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('processed/sec_occ_wage/*.csv')\n",
    "\n",
    "sec_wage = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    year = int(os.path.basename(file)[-8:-4])\n",
    "    current = pd.read_csv(file)\n",
    "    current['sector_total'] = current.iloc[:, 1:].sum(axis=1)\n",
    "    current = current.melt(id_vars=['INDNAICS'], var_name='Occupation', value_name='Wage')\n",
    "    current['Year'] = year\n",
    "    sec_wage = pd.concat([sec_wage, current], ignore_index=True)\n",
    "\n",
    "sec_wage.to_csv('aggregate/sector_occupation_wage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('raw/data_new.csv', assume_missing=True, dtype={'INDNAICS': 'string'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('raw/usa_00010.csv', assume_missing=True, dtype={'INDNAICS': 'string'})\n",
    "df = df[['MET2013', 'METAREA']]\n",
    "df = df.drop_duplicates(subset=['MET2013', 'METAREA'])\n",
    "df = df.compute()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_csv('raw/usa_00015.csv')\n",
    "df = df.filter(pl.col('YEAR') == 2019).collect()\n",
    "\n",
    "# df = df.with_columns(\n",
    "#     pl.col('OCC1990').map_elements(map_occupations, return_dtype=pl.Utf8).alias('occupation')\n",
    "# )\n",
    "\n",
    "# years = df.filter(pl.col('YEAR').is_not_null()).select(pl.col('YEAR').unique()).collect().to_series()\n",
    "# current = df.filter(pl.col('YEAR') == year).collect().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Creating occupation mappings...\n",
      "Creating area mappings...\n",
      "Mapping sectors...\n"
     ]
    }
   ],
   "source": [
    "mappings = [\n",
    "    ((405, 408), 'occ3_clean'),\n",
    "    ((415, 427), 'occ3_protect'),\n",
    "    ((415, 415), 'occ3_guard'),\n",
    "    ((425, 427), 'occ3_guard'),\n",
    "    ((433, 444), 'occ3_food'),\n",
    "    ((445, 447), 'occ3_shealth'),\n",
    "    ((448, 455), 'occ3_janitor'),\n",
    "    ((457, 458), 'occ3_beauty'),\n",
    "    ((459, 467), 'occ3_recreation'),\n",
    "    ((468, 468), 'occ3_child'),\n",
    "    ((469, 472), 'occ3_others'),\n",
    "    ((3, 22), 'occ2_exec'),\n",
    "    ((23, 37), 'occ2_mgmtrel'),\n",
    "    ((43, 200), 'occ2_prof'),\n",
    "    ((203, 235), 'occ2_tech'),\n",
    "    ((243, 258), 'occ2_finsales'),\n",
    "    ((274, 283), 'occ2_retsales'),\n",
    "    ((303, 389), 'occ2_cleric'),\n",
    "    ((417, 423), 'occ2_firepol'),\n",
    "    ((473, 475), 'occ2_farmer'),\n",
    "    ((479, 498), 'occ2_otheragr'),\n",
    "    ((503, 549), 'occ2_mechanic'),\n",
    "    ((558, 599), 'occ2_constr'),\n",
    "    ((614, 617), 'occ2_mining'),\n",
    "    ((628, 699), 'occ2_product'),\n",
    "    ((703, 799), 'occ2_operator'),\n",
    "    ((803, 889), 'occ2_transp'),\n",
    "]\n",
    "\n",
    "def map_occupations(occ1990dd):\n",
    "    for (start, end), occupation in mappings:\n",
    "        if start <= occ1990dd <= end:\n",
    "            return occupation\n",
    "    return 'other'\n",
    "\n",
    "def expand_ranges(df):\n",
    "    expanded_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        if '-' in index:\n",
    "            start, end = map(int, index.split('-'))\n",
    "            for i in range(start, end + 1):\n",
    "                expanded_rows.append((str(i), row['Name']))\n",
    "        else:\n",
    "            expanded_rows.append((index, row['Name']))\n",
    "    return pd.DataFrame(expanded_rows, columns=['Sector', 'Name']).set_index('Sector')\n",
    "\n",
    "print('Reading data...')\n",
    "df = pl.scan_csv('raw/usa_00015.csv')\n",
    "met_codes = pd.read_csv('raw/met_codes.csv')\n",
    "met_codes.set_index('code', inplace=True)\n",
    "\n",
    "print('Creating occupation mappings...')\n",
    "df = df.with_columns(\n",
    "    pl.col('OCC1990').map_elements(map_occupations, return_dtype=pl.Utf8).alias('occupation')\n",
    ")\n",
    "\n",
    "print('Creating area mappings...')\n",
    "df_cz = pd.read_csv('raw/cz_mappings.csv')\n",
    "df_cz = df_cz[['LMA/CZ', 'FIPS']]\n",
    "df = df.with_columns(\n",
    "    (pl.col('STATEFIP').cast(pl.Int32) * 1000 + pl.col('COUNTYFIP').cast(pl.Int32)).alias('FIPS')\n",
    ")\n",
    "\n",
    "print('Mapping sectors...')\n",
    "df = df.with_columns(\n",
    "    pl.col('INDNAICS').cast(pl.Utf8).str.slice(0, 2).alias('INDNAICS')\n",
    ")\n",
    "naics_codes = pd.read_csv('raw/2022_NAICS_codes.csv')\n",
    "naics_codes = naics_codes[['Sector', 'Name']]\n",
    "naics_codes.dropna(inplace=True)\n",
    "naics_codes.set_index('Sector', inplace=True)\n",
    "naics_codes.loc['0'] = 'N/A'\n",
    "naics_codes.loc['99'] = 'Unemployed'\n",
    "naics_codes.loc['50'] = 'Transportation and Warehousing'\n",
    "naics_codes.loc['3M'] = 'Manufacturing'\n",
    "naics_codes = expand_ranges(naics_codes)\n",
    "\n",
    "years = df.filter(pl.col('YEAR').is_not_null()).select(pl.col('YEAR').unique()).collect().to_series()\n",
    "\n",
    "area = 'COMZONE'\n",
    "\n",
    "current = df.filter(pl.col('YEAR') == 1980).collect()\n",
    "\n",
    "current = current.with_columns(\n",
    "    pl.col('INCWAGE').cast(pl.Float64),\n",
    "    pl.col('RENT').cast(pl.Float64),\n",
    "    pl.col('HHWT').cast(pl.Float64),\n",
    "    pl.col('INDNAICS').cast(pl.Utf8),\n",
    ")\n",
    "\n",
    "current = current.with_columns(\n",
    "    (pl.col('INCWAGE') * pl.col('HHWT')).alias('INCWAGE'),\n",
    "    (pl.col('INCWAGE') / pl.col('HHWT')).alias('AVERAGE INCWAGE'),\n",
    "    (pl.col('RENT') * pl.col('HHWT')).alias('RENT'),\n",
    ")\n",
    "\n",
    "# current['INCWAGE'] = current['INCWAGE'] * current['HHWT']\n",
    "# current['AVERAGE INCWAGE'] = current['INCWAGE'] / current['HHWT']\n",
    "# current['RENT'] = current['RENT'] * current['HHWT']\n",
    "\n",
    "current = current.with_columns(\n",
    "    (pl.col('RENT').drop_nulls().cast(pl.Int32) * pl.col('HHWT')).alias('HH_RENT')\n",
    ")\n",
    "\n",
    "# current['HH_RENT'] = current['RENT'].notnull().astype(int)\n",
    "# current['HH_RENT'] = current['HH_RENT'] * current['HHWT']\n",
    "\n",
    "naics_keys = naics_codes.index.tolist()\n",
    "naics_values = naics_codes['Name'].tolist()\n",
    "\n",
    "fips_keys = df_cz.set_index('FIPS')['LMA/CZ'].index.tolist()\n",
    "fips_values = df_cz.set_index('FIPS')['LMA/CZ'].tolist()\n",
    "\n",
    "current = current.with_columns(\n",
    "    pl.col('INDNAICS').replace(naics_keys, naics_values),\n",
    "    pl.col('FIPS').replace(fips_keys, fips_values).alias('COMZONE')\n",
    ")\n",
    "\n",
    "# current['INDNAICS'] = current['INDNAICS'].map(naics_codes['Name'])\n",
    "# current['COMZONE'] = current['FIPS'].map(df_cz.set_index('FIPS')['LMA/CZ'])\n",
    "\n",
    "city_occ = current.pivot(index=area, on='occupation', values='HHWT', aggregate_function='sum')\n",
    "city_occ_wage = current.pivot(index=area, on='occupation', values='AVERAGE INCWAGE', aggregate_function='mean')\n",
    "city_sector_wage = current.pivot(index=area, on='INDNAICS', values='INCWAGE', aggregate_function='sum')\n",
    "sector_occ_wage = current.pivot(index=area, on='occupation', values='INCWAGE', aggregate_function='sum')\n",
    "\n",
    "city_rent = current.pivot(index=area, on='RENT', aggregate_function='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cw = pd.read_stata('raw/cw_ctygrp1980_czone_corr.dta')\n",
    "df_cw = df_cw.rename(columns={'ctygrp1980': 'puma1980'})\n",
    "df = df.merge(df_cw, on='puma1980', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_occ = df.pivot_table(index='czone', columns='OCC1990', values='HHWT', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_458393/283644184.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, current], ignore_index=True)\n",
      "/tmp/ipykernel_458393/283644184.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, current], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_cw = pd.read_csv('raw/cw_puma2000_czone.csv', encoding='latin1')\n",
    "# df_names = pd.read_csv('raw/puma_names.csv')\n",
    "# df_names['puma2000'] = df_names['State10'] * 10000 + df_names['PUMA10']\n",
    "# df_names = df_names[['puma2000', 'PUMA10_Name']]\n",
    "df_names = pd.read_csv('raw/cz_names.csv')\n",
    "df_cw = df_cw.merge(df_names, on='czone', how='left')\n",
    "df_cw = df_cw.sort_values(by=['czone', 'afactor'])\n",
    "df_cw = df_cw.drop_duplicates(subset=['czone'])\n",
    "df_cw = df_cw[['czone', 'County Name']]\n",
    "df_cw = df_cw.rename(columns={'czone': 'COMZONE', 'County Name': 'NAME'})\n",
    "\n",
    "def get_data(directory, field_name):\n",
    "    files = glob.glob(directory)\n",
    "    files = [f for f in files if re.search(r'_(1980|199[0-9]|20[0-9]{2})\\.csv$', f)]\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for file in files:\n",
    "        year = int(os.path.basename(file)[-8:-4])\n",
    "        current = pd.read_csv(file)\n",
    "        # current['city_total'] = current.iloc[:, 1:].sum(axis=1)\n",
    "        current = current.melt(id_vars=['COMZONE'], var_name='Occupation', value_name=field_name)\n",
    "        current['Year'] = year\n",
    "        data = pd.concat([data, current], ignore_index=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "employment = get_data('processed/city_occ_employment/*.csv', 'Employed')\n",
    "employment = employment.merge(df_cw, on='COMZONE', how='left')\n",
    "employment = employment[['Year', 'COMZONE', 'NAME', 'Occupation', 'Employed']]\n",
    "\n",
    "# wage = get_data('processed/city_occ_wage/*.csv', 'Wage')\n",
    "wb = get_data('processed/city_occ_wb/*.csv', 'Wage_Bill')\n",
    "\n",
    "# final = employment.merge(wage, on=['Year', 'COMZONE', 'Occupation'], how='left')\n",
    "final = employment.merge(wb, on=['Year', 'COMZONE', 'Occupation'], how='left')\n",
    "# final.to_csv('master.csv', index=False)\n",
    "\n",
    "df_cpi = pd.read_csv('raw/CPI.csv')\n",
    "df_cpi['DATE'] = pd.to_datetime(df_cpi['DATE'])\n",
    "df_cpi['Year'] = df_cpi['DATE'].dt.year\n",
    "df_cpi['month'] = df_cpi['DATE'].dt.month\n",
    "df_cpi = df_cpi[df_cpi['month'] == 12]\n",
    "df_cpi = df_cpi.rename(columns={'CPIAUCSL': 'CPI'})\n",
    "df_cpi = df_cpi[['Year', 'CPI']]\n",
    "\n",
    "base_year = 1990\n",
    "\n",
    "final = final.merge(df_cpi, on='Year', how='left')\n",
    "final['Wage'] = final['Wage_Bill'] / final['Employed']\n",
    "final['Wage_Bill'] = (final['Wage_Bill'] / final['CPI']) * df_cpi[df_cpi['Year'] == base_year]['CPI'].values[0]\n",
    "final = final[['Year', 'COMZONE', 'NAME', 'Occupation', 'Employed', 'Wage', 'Wage_Bill', 'CPI']]\n",
    "\n",
    "total_years = final['Year'].nunique()\n",
    "occupation_counts = final.groupby('Occupation')['Year'].nunique()\n",
    "valid_occupations = occupation_counts[occupation_counts == total_years].index\n",
    "\n",
    "final = final[final['Occupation'].isin(valid_occupations)]\n",
    "\n",
    "occupations = final['Occupation'].unique().tolist()\n",
    "cities = final['COMZONE'].unique().tolist()\n",
    "years = final['Year'].unique().tolist()\n",
    "occupation_indices = {occupation: idx for idx, occupation in enumerate(occupations)}\n",
    "city_indices = {city: idx for idx, city in enumerate(cities)}\n",
    "year_indices = {year: idx for idx, year in enumerate(years)}\n",
    "\n",
    "final['c'] = final['COMZONE'].map(city_indices)\n",
    "final['k'] = final['Occupation'].map(occupation_indices)\n",
    "final['t'] = final['Year'].map(year_indices)\n",
    "final['ckt'] = final['c'].astype(str) + final['k'].astype(str) + final['t'].astype(str)\n",
    "\n",
    "# final.to_csv('master.csv', index=False)\n",
    "\n",
    "# final = pd.read_csv('master.csv')\n",
    "\n",
    "years = [1990, 2000, 2009, 2018]\n",
    "final = final[final['Year'].isin(years)]\n",
    "final.to_csv('master_subset.csv', index=False)\n",
    "\n",
    "occupation_df = pd.DataFrame(list(occupation_indices.items()), columns=['Occupation', 'Index'])\n",
    "city_df = pd.DataFrame(list(city_indices.items()), columns=['City', 'Index'])\n",
    "year_df = pd.DataFrame(list(year_indices.items()), columns=['Year', 'Index'])\n",
    "# occupation_df.to_csv('occupation_indices.csv', index=False)\n",
    "# city_df.to_csv('city_indices.csv', index=False)\n",
    "# year_df.to_csv('year_indices.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_names_cw = pd.read_csv('raw/puma_fips.csv')\n",
    "df_names = pd.read_csv('raw/cz_mappings.csv')\n",
    "df_pop = pd.read_csv('raw/archive/cz_county.csv')\n",
    "df_puma_cz = pd.read_csv('raw/cw_puma2000_czone.csv', encoding='latin1')\n",
    "\n",
    "df_names_cw['puma2000'] = df_names_cw['STATEFP'] * 10000 + df_names_cw['PUMA5CE']\n",
    "df_names_cw['FIPS'] = df_names_cw['STATEFP'] * 1000 + df_names_cw['COUNTYFP']\n",
    "df_names_cw = df_names_cw.drop_duplicates(subset=['puma2000', 'FIPS'])\n",
    "df_names_cw = df_names_cw[['puma2000', 'FIPS']]\n",
    "\n",
    "df_names = df_names[['FIPS', 'County Name']]\n",
    "df_names_cw = df_names_cw.merge(df_names, on='FIPS', how='left')\n",
    "\n",
    "df_names_cw = df_names_cw.merge(df_pop[['FIPS', 'Labor Force']], on='FIPS', how='left')\n",
    "\n",
    "df_names_cw = df_names_cw.merge(df_puma_cz, on='puma2000', how='left')\n",
    "\n",
    "idx = df_names_cw.groupby(['czone'])['Labor Force'].idxmax()\n",
    "df_names_cw = df_names_cw.loc[idx].reset_index(drop=True)\n",
    "df_names_cw = df_names_cw[['czone', 'County Name']]\n",
    "\n",
    "# df_names_cw.to_csv('raw/cz_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_ranges(df):\n",
    "    expanded_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        if '-' in index:\n",
    "            start, end = map(int, index.split('-'))\n",
    "            for i in range(start, end + 1):\n",
    "                expanded_rows.append((str(i), row['Name']))\n",
    "        else:\n",
    "            expanded_rows.append((index, row['Name']))\n",
    "    return pd.DataFrame(expanded_rows, columns=['Sector', 'Name']).set_index('Sector')\n",
    "\n",
    "naics_codes = pd.read_csv('raw/2022_NAICS_codes.csv')\n",
    "naics_codes = naics_codes[['Sector', 'Name']]\n",
    "naics_codes.dropna(inplace=True)\n",
    "naics_codes.set_index('Sector', inplace=True)\n",
    "naics_codes.loc['0'] = 'N/A'\n",
    "naics_codes.loc['99'] = 'Unemployed'\n",
    "naics_codes.loc['50'] = 'Transportation and Warehousing'\n",
    "naics_codes.loc['3M'] = 'Manufacturing'\n",
    "naics_codes = expand_ranges(naics_codes)\n",
    "\n",
    "sic_to_naics = pd.read_csv('raw/full_sic87_naics97.csv')\n",
    "sic_to_naics = sic_to_naics[['sic87', 'naics97']]\n",
    "sic_to_naics = sic_to_naics.drop_duplicates(subset=['sic87'])\n",
    "\n",
    "city_sec = pd.read_csv('raw/efsy_cbp_1980.csv')\n",
    "city_sec['naics'] = city_sec['naics'].map(sic_to_naics.set_index('sic87')['naics97'])\n",
    "city_sec['naics'] = city_sec['naics'].str[:2].replace('--', '0').astype(str)\n",
    "city_sec['fips'] = city_sec['fipstate'] * 1000 + city_sec['fipscty']\n",
    "city_sec = city_sec.groupby(['naics', 'fips']).agg({\n",
    "    'ub': 'sum',\n",
    "    'lb': 'sum',\n",
    "    'fipstate': 'first',\n",
    "    'fipscty': 'first',\n",
    "}).reset_index()\n",
    "city_sec['employment'] = (city_sec['ub'] + city_sec['lb']) / 2\n",
    "city_sec['naics'] = city_sec['naics'].map(naics_codes['Name'])\n",
    "# city_sec = city_sec.drop_duplicates(subset=['fips', 'naics'])\n",
    "# city_sec = city_sec.pivot(index='fips', columns='naics', values='employment')\n",
    "\n",
    "df_names_cw = pd.read_csv('raw/puma_fips.csv')\n",
    "df_names = pd.read_csv('raw/cz_mappings.csv')\n",
    "df_puma_cz = pd.read_csv('raw/cw_puma2000_czone.csv', encoding='latin1')\n",
    "df_cz_names = pd.read_csv('raw/cz_names.csv')\n",
    "\n",
    "df_names_cw['puma2000'] = df_names_cw['STATEFP'] * 10000 + df_names_cw['PUMA5CE']\n",
    "df_names_cw['FIPS'] = df_names_cw['STATEFP'] * 1000 + df_names_cw['COUNTYFP']\n",
    "df_names_cw = df_names_cw.drop_duplicates(subset=['puma2000', 'FIPS'])\n",
    "df_names_cw = df_names_cw[['puma2000', 'FIPS']]\n",
    "\n",
    "df_names = df_names[['FIPS', 'County Name']]\n",
    "df_names_cw = df_names_cw.merge(df_names, on='FIPS', how='left')\n",
    "\n",
    "df_names_cw = df_names_cw.merge(df_puma_cz, on='puma2000', how='left')\n",
    "df_names_cw = df_names_cw[['FIPS', 'czone']]\n",
    "df_names_cw = df_names_cw.drop_duplicates(subset=['FIPS'])\n",
    "\n",
    "city_sec = city_sec.merge(df_names_cw, left_on='fips', right_on='FIPS', how='left')\n",
    "city_sec['czone_name'] = city_sec['czone'].map(df_cz_names.set_index('czone')['County Name'])\n",
    "city_sec = city_sec.drop_duplicates(subset=['czone', 'naics'])\n",
    "city_sec = city_sec[['czone', 'czone_name', 'naics', 'employment']]\n",
    "city_sec.to_csv('processed/city_sec_employment_1980.csv', index=False)\n",
    "# city_sec = city_sec.pivot(index='czone', columns='naics', values='employment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpi = pd.read_csv('raw/CPI.csv')\n",
    "df_cpi['DATE'] = pd.to_datetime(df_cpi['DATE'])\n",
    "df_cpi['year'] = df_cpi['DATE'].dt.year\n",
    "df_cpi['month'] = df_cpi['DATE'].dt.month\n",
    "df_cpi = df_cpi[df_cpi['month'] == 12]\n",
    "df_cpi = df_cpi.rename(columns={'CPIAUCSL': 'CPI'})\n",
    "df_cpi = df_cpi[['year', 'CPI']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46983/1870073691.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, current], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def get_data(directory, field_name, id_vars=['COMZONE'], var_name='Occupation'):\n",
    "    files = glob.glob(directory)\n",
    "    files = [f for f in files if re.search(r'_(1980|199[0-9]|20[0-9]{2})\\.csv$', f)]\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for file in files:\n",
    "        year = int(os.path.basename(file)[-8:-4])\n",
    "        current = pd.read_csv(file)\n",
    "        current['city_total'] = current.iloc[:, 1:].sum(axis=1)\n",
    "        current = current.melt(id_vars=id_vars, var_name=var_name, value_name=field_name)\n",
    "        current['Year'] = year\n",
    "        data = pd.concat([data, current], ignore_index=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "city_sec_employment = get_data('processed/city_sec_employment/*.csv', 'Employed', id_vars=['COMZONE'], var_name='Sector')\n",
    "sector_occ_wage = get_data('processed/sec_occ_wb/*.csv', 'Wage', id_vars=['INDNAICS'], var_name='Occupation')\n",
    "\n",
    "years = [1990, 2000, 2010, 2018]\n",
    "city_sec_employment = city_sec_employment[city_sec_employment['Year'].isin(years)]\n",
    "sector_occ_wage = sector_occ_wage[sector_occ_wage['Year'].isin(years)]\n",
    "\n",
    "city_sec_employment.to_csv('city_sector_employment_subset.csv', index=False)\n",
    "sector_occ_wage.to_csv('sector_occ_wb_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddx_1990 = pd.read_stata('raw/crosswalk/cw_ind1990_ind1990ddx.dta')\n",
    "sic_1990 = pd.read_stata('raw/crosswalk/cw_sic87_ind1990ddx.dta')\n",
    "sic_naics = pd.read_stata('raw/crosswalk/cw_n97_s87.dta')\n",
    "\n",
    "sic_1990 = sic_1990.merge(ddx_1990, on='ind1990ddx', how='outer')\n",
    "naics_1990 = sic_naics.merge(sic_1990, left_on='sic4', right_on='sic87', how='inner')\n",
    "naics_1990 = naics_1990[['naics6', 'ind1990']]\n",
    "naics_1990 = naics_1990.drop_duplicates(subset=['naics6', 'ind1990'])\n",
    "\n",
    "naics_1990.to_csv('raw/crosswalk/naics_1990.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_ranges(df):\n",
    "    expanded_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        if '-' in index:\n",
    "            start, end = map(int, index.split('-'))\n",
    "            for i in range(start, end + 1):\n",
    "                expanded_rows.append((str(i), row['Name']))\n",
    "        else:\n",
    "            expanded_rows.append((index, row['Name']))\n",
    "    return pd.DataFrame(expanded_rows, columns=['Sector', 'Name']).set_index('Sector')\n",
    "\n",
    "df = pl.scan_csv('raw/usa_00020.csv')\n",
    "df = df.with_columns(\n",
    "    (pl.col('STATEFIP').cast(pl.Int32) * 10000 + pl.col('PUMA').cast(pl.Int32)).alias('FIPS'),\n",
    "    (pl.col('STATEFIP').cast(pl.Int32) * 1000 + pl.col('CNTYGP98').cast(pl.Int32)).alias('ctygrp1980'),\n",
    ")\n",
    "df = df.filter(pl.col('YEAR') == 1990).collect().to_pandas()\n",
    "\n",
    "df_cz_1990 = pd.read_csv('raw/cw_puma1990_czone.csv', encoding='latin1')\n",
    "df = df.merge(df_cz_1990, left_on='FIPS', right_on='puma1990', how='left')\n",
    "df['COMZONE'] = df['czone']\n",
    "\n",
    "df_cz = pd.read_csv('raw/crosswalk/naics_1990.csv')\n",
    "df_cz['naics2'] = df_cz['naics6'].astype(str).str[:2]\n",
    "df_cz = df_cz[['naics2', 'ind1990']]\n",
    "df_cz = df_cz.drop_duplicates(subset=['naics2', 'ind1990'])\n",
    "\n",
    "df = df.merge(df_cz, left_on='IND1990', right_on='ind1990', how='left')\n",
    "\n",
    "naics_codes = pd.read_csv('raw/2022_NAICS_codes.csv')\n",
    "naics_codes = naics_codes[['Sector', 'Name']]\n",
    "naics_codes.dropna(inplace=True)\n",
    "naics_codes.set_index('Sector', inplace=True)\n",
    "naics_codes.loc['0'] = 'N/A'\n",
    "naics_codes.loc['99'] = 'Unemployed'\n",
    "naics_codes.loc['50'] = 'Transportation and Warehousing'\n",
    "naics_codes.loc['3M'] = 'Manufacturing'\n",
    "naics_codes = expand_ranges(naics_codes)\n",
    "\n",
    "df['naics2'] = df['naics2'].map(naics_codes['Name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geofence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
