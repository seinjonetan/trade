{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import polars as pl\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('processed/city_sec_wage/*.csv')\n",
    "\n",
    "wage = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    year = int(os.path.basename(file)[-8:-4])\n",
    "    current = pd.read_csv(file)\n",
    "    current['city_total'] = current.iloc[:, 1:].sum(axis=1)\n",
    "    current = current.melt(id_vars=['MET2013'], var_name='Sector', value_name='Wage')\n",
    "    current['Year'] = year\n",
    "    wage = pd.concat([wage, current], ignore_index=True)\n",
    "\n",
    "wage.to_csv('aggregate/city_sector_wage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('processed/sec_occ_wage/*.csv')\n",
    "\n",
    "sec_wage = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    year = int(os.path.basename(file)[-8:-4])\n",
    "    current = pd.read_csv(file)\n",
    "    current['sector_total'] = current.iloc[:, 1:].sum(axis=1)\n",
    "    current = current.melt(id_vars=['INDNAICS'], var_name='Occupation', value_name='Wage')\n",
    "    current['Year'] = year\n",
    "    sec_wage = pd.concat([sec_wage, current], ignore_index=True)\n",
    "\n",
    "sec_wage.to_csv('aggregate/sector_occupation_wage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>MET2013</th>\n",
       "      <th>STRATA</th>\n",
       "      <th>GQ</th>\n",
       "      <th>OWNCOST</th>\n",
       "      <th>RENT</th>\n",
       "      <th>RENTGRS</th>\n",
       "      <th>PERNUM</th>\n",
       "      <th>PERWT</th>\n",
       "      <th>IND1990</th>\n",
       "      <th>INDNAICS</th>\n",
       "      <th>INCWAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>197003.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.970000e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>197003.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.970000e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>197003.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.970000e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>197003.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.970000e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>197003.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.970000e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5950.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR    SAMPLE  SERIAL  CBSERIAL   HHWT       CLUSTER  MET2013  STRATA  \\\n",
       "0  1970.0  197003.0     1.0       NaN  100.0  1.970000e+12      NaN     6.0   \n",
       "1  1970.0  197003.0     3.0       NaN  100.0  1.970000e+12      NaN    70.0   \n",
       "2  1970.0  197003.0     4.0       NaN  100.0  1.970000e+12      NaN    48.0   \n",
       "3  1970.0  197003.0     4.0       NaN  100.0  1.970000e+12      NaN    48.0   \n",
       "4  1970.0  197003.0     5.0       NaN  100.0  1.970000e+12      NaN    61.0   \n",
       "\n",
       "    GQ  OWNCOST  RENT  RENTGRS  PERNUM  PERWT  IND1990 INDNAICS  INCWAGE  \n",
       "0  3.0      NaN   0.0      0.0     1.0  100.0    842.0     <NA>   1250.0  \n",
       "1  1.0      NaN   0.0      0.0     1.0  100.0      0.0     <NA>      0.0  \n",
       "2  1.0      NaN  75.0     75.0     1.0  100.0    612.0     <NA>   4050.0  \n",
       "3  1.0      NaN  75.0     75.0     2.0  100.0    842.0     <NA>   1350.0  \n",
       "4  1.0      NaN   0.0      0.0     1.0  100.0    910.0     <NA>   5950.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dd.read_csv('raw/data_new.csv', assume_missing=True, dtype={'INDNAICS': 'string'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('raw/usa_00010.csv', assume_missing=True, dtype={'INDNAICS': 'string'})\n",
    "df = df[['MET2013', 'METAREA']]\n",
    "df = df.drop_duplicates(subset=['MET2013', 'METAREA'])\n",
    "df = df.compute()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_csv('raw/usa_00015.csv')\n",
    "df = df.filter(pl.col('YEAR') == 2019).collect()\n",
    "\n",
    "# df = df.with_columns(\n",
    "#     pl.col('OCC1990').map_elements(map_occupations, return_dtype=pl.Utf8).alias('occupation')\n",
    "# )\n",
    "\n",
    "# years = df.filter(pl.col('YEAR').is_not_null()).select(pl.col('YEAR').unique()).collect().to_series()\n",
    "# current = df.filter(pl.col('YEAR') == year).collect().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Creating occupation mappings...\n",
      "Creating area mappings...\n",
      "Mapping sectors...\n"
     ]
    }
   ],
   "source": [
    "mappings = [\n",
    "    ((405, 408), 'occ3_clean'),\n",
    "    ((415, 427), 'occ3_protect'),\n",
    "    ((415, 415), 'occ3_guard'),\n",
    "    ((425, 427), 'occ3_guard'),\n",
    "    ((433, 444), 'occ3_food'),\n",
    "    ((445, 447), 'occ3_shealth'),\n",
    "    ((448, 455), 'occ3_janitor'),\n",
    "    ((457, 458), 'occ3_beauty'),\n",
    "    ((459, 467), 'occ3_recreation'),\n",
    "    ((468, 468), 'occ3_child'),\n",
    "    ((469, 472), 'occ3_others'),\n",
    "    ((3, 22), 'occ2_exec'),\n",
    "    ((23, 37), 'occ2_mgmtrel'),\n",
    "    ((43, 200), 'occ2_prof'),\n",
    "    ((203, 235), 'occ2_tech'),\n",
    "    ((243, 258), 'occ2_finsales'),\n",
    "    ((274, 283), 'occ2_retsales'),\n",
    "    ((303, 389), 'occ2_cleric'),\n",
    "    ((417, 423), 'occ2_firepol'),\n",
    "    ((473, 475), 'occ2_farmer'),\n",
    "    ((479, 498), 'occ2_otheragr'),\n",
    "    ((503, 549), 'occ2_mechanic'),\n",
    "    ((558, 599), 'occ2_constr'),\n",
    "    ((614, 617), 'occ2_mining'),\n",
    "    ((628, 699), 'occ2_product'),\n",
    "    ((703, 799), 'occ2_operator'),\n",
    "    ((803, 889), 'occ2_transp'),\n",
    "]\n",
    "\n",
    "def map_occupations(occ1990dd):\n",
    "    for (start, end), occupation in mappings:\n",
    "        if start <= occ1990dd <= end:\n",
    "            return occupation\n",
    "    return 'other'\n",
    "\n",
    "def expand_ranges(df):\n",
    "    expanded_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        if '-' in index:\n",
    "            start, end = map(int, index.split('-'))\n",
    "            for i in range(start, end + 1):\n",
    "                expanded_rows.append((str(i), row['Name']))\n",
    "        else:\n",
    "            expanded_rows.append((index, row['Name']))\n",
    "    return pd.DataFrame(expanded_rows, columns=['Sector', 'Name']).set_index('Sector')\n",
    "\n",
    "print('Reading data...')\n",
    "df = pl.scan_csv('raw/usa_00015.csv')\n",
    "met_codes = pd.read_csv('raw/met_codes.csv')\n",
    "met_codes.set_index('code', inplace=True)\n",
    "\n",
    "print('Creating occupation mappings...')\n",
    "df = df.with_columns(\n",
    "    pl.col('OCC1990').map_elements(map_occupations, return_dtype=pl.Utf8).alias('occupation')\n",
    ")\n",
    "\n",
    "print('Creating area mappings...')\n",
    "df_cz = pd.read_csv('raw/cz_mappings.csv')\n",
    "df_cz = df_cz[['LMA/CZ', 'FIPS']]\n",
    "df = df.with_columns(\n",
    "    (pl.col('STATEFIP').cast(pl.Int32) * 1000 + pl.col('COUNTYFIP').cast(pl.Int32)).alias('FIPS')\n",
    ")\n",
    "\n",
    "print('Mapping sectors...')\n",
    "df = df.with_columns(\n",
    "    pl.col('INDNAICS').cast(pl.Utf8).str.slice(0, 2).alias('INDNAICS')\n",
    ")\n",
    "naics_codes = pd.read_csv('raw/2022_NAICS_codes.csv')\n",
    "naics_codes = naics_codes[['Sector', 'Name']]\n",
    "naics_codes.dropna(inplace=True)\n",
    "naics_codes.set_index('Sector', inplace=True)\n",
    "naics_codes.loc['0'] = 'N/A'\n",
    "naics_codes.loc['99'] = 'Unemployed'\n",
    "naics_codes.loc['50'] = 'Transportation and Warehousing'\n",
    "naics_codes.loc['3M'] = 'Manufacturing'\n",
    "naics_codes = expand_ranges(naics_codes)\n",
    "\n",
    "years = df.filter(pl.col('YEAR').is_not_null()).select(pl.col('YEAR').unique()).collect().to_series()\n",
    "\n",
    "area = 'COMZONE'\n",
    "\n",
    "current = df.filter(pl.col('YEAR') == 1980).collect()\n",
    "\n",
    "current = current.with_columns(\n",
    "    pl.col('INCWAGE').cast(pl.Float64),\n",
    "    pl.col('RENT').cast(pl.Float64),\n",
    "    pl.col('HHWT').cast(pl.Float64),\n",
    "    pl.col('INDNAICS').cast(pl.Utf8),\n",
    ")\n",
    "\n",
    "current = current.with_columns(\n",
    "    (pl.col('INCWAGE') * pl.col('HHWT')).alias('INCWAGE'),\n",
    "    (pl.col('INCWAGE') / pl.col('HHWT')).alias('AVERAGE INCWAGE'),\n",
    "    (pl.col('RENT') * pl.col('HHWT')).alias('RENT'),\n",
    ")\n",
    "\n",
    "# current['INCWAGE'] = current['INCWAGE'] * current['HHWT']\n",
    "# current['AVERAGE INCWAGE'] = current['INCWAGE'] / current['HHWT']\n",
    "# current['RENT'] = current['RENT'] * current['HHWT']\n",
    "\n",
    "current = current.with_columns(\n",
    "    (pl.col('RENT').drop_nulls().cast(pl.Int32) * pl.col('HHWT')).alias('HH_RENT')\n",
    ")\n",
    "\n",
    "# current['HH_RENT'] = current['RENT'].notnull().astype(int)\n",
    "# current['HH_RENT'] = current['HH_RENT'] * current['HHWT']\n",
    "\n",
    "naics_keys = naics_codes.index.tolist()\n",
    "naics_values = naics_codes['Name'].tolist()\n",
    "\n",
    "fips_keys = df_cz.set_index('FIPS')['LMA/CZ'].index.tolist()\n",
    "fips_values = df_cz.set_index('FIPS')['LMA/CZ'].tolist()\n",
    "\n",
    "current = current.with_columns(\n",
    "    pl.col('INDNAICS').replace(naics_keys, naics_values),\n",
    "    pl.col('FIPS').replace(fips_keys, fips_values).alias('COMZONE')\n",
    ")\n",
    "\n",
    "# current['INDNAICS'] = current['INDNAICS'].map(naics_codes['Name'])\n",
    "# current['COMZONE'] = current['FIPS'].map(df_cz.set_index('FIPS')['LMA/CZ'])\n",
    "\n",
    "city_occ = current.pivot(index=area, on='occupation', values='HHWT', aggregate_function='sum')\n",
    "city_occ_wage = current.pivot(index=area, on='occupation', values='AVERAGE INCWAGE', aggregate_function='mean')\n",
    "city_sector_wage = current.pivot(index=area, on='INDNAICS', values='INCWAGE', aggregate_function='sum')\n",
    "sector_occ_wage = current.pivot(index=area, on='occupation', values='INCWAGE', aggregate_function='sum')\n",
    "\n",
    "city_rent = current.pivot(index=area, on='RENT', aggregate_function='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_csv('raw/usa_00019.csv')\n",
    "df_cz = pd.read_csv('raw/cw_puma1990_czone.csv', encoding='latin1')\n",
    "df = df.with_columns(\n",
    "    (pl.col('STATEFIP').cast(pl.Int32) * 1000 + pl.col('CNTYGP98').cast(pl.Int32)).alias('puma1980')\n",
    ")\n",
    "df = df.filter(pl.col('YEAR') == 1980).collect().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cw = pd.read_stata('raw/cw_ctygrp1980_czone_corr.dta')\n",
    "df_cw = df_cw.rename(columns={'ctygrp1980': 'puma1980'})\n",
    "df = df.merge(df_cw, on='puma1980', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_occ = df.pivot_table(index='czone', columns='OCC1990', values='HHWT', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_372220/1737793232.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, current], ignore_index=True)\n",
      "/tmp/ipykernel_372220/1737793232.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, current], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_cw = pd.read_csv('raw/cw_puma2000_czone.csv', encoding='latin1')\n",
    "# df_names = pd.read_csv('raw/puma_names.csv')\n",
    "# df_names['puma2000'] = df_names['State10'] * 10000 + df_names['PUMA10']\n",
    "# df_names = df_names[['puma2000', 'PUMA10_Name']]\n",
    "df_names = pd.read_csv('raw/cz_names.csv')\n",
    "df_cw = df_cw.merge(df_names, on='czone', how='left')\n",
    "df_cw = df_cw.sort_values(by=['czone', 'afactor'])\n",
    "df_cw = df_cw.drop_duplicates(subset=['czone'])\n",
    "df_cw = df_cw[['czone', 'County Name']]\n",
    "df_cw = df_cw.rename(columns={'czone': 'COMZONE', 'County Name': 'NAME'})\n",
    "\n",
    "def get_data(directory, field_name):\n",
    "    files = glob.glob(directory)\n",
    "    files = [f for f in files if re.search(r'_(1980|199[0-9]|20[0-9]{2})\\.csv$', f)]\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for file in files:\n",
    "        year = int(os.path.basename(file)[-8:-4])\n",
    "        current = pd.read_csv(file)\n",
    "        current['city_total'] = current.iloc[:, 1:].sum(axis=1)\n",
    "        current = current.melt(id_vars=['COMZONE'], var_name='Occupation', value_name=field_name)\n",
    "        current['Year'] = year\n",
    "        data = pd.concat([data, current], ignore_index=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "employment = get_data('processed/city_occ_employment/*.csv', 'Employed')\n",
    "employment = employment.merge(df_cw, on='COMZONE', how='left')\n",
    "employment = employment[['Year', 'COMZONE', 'NAME', 'Occupation', 'Employed']]\n",
    "\n",
    "# wage = get_data('processed/city_occ_wage/*.csv', 'Wage')\n",
    "wb = get_data('processed/city_occ_wb/*.csv', 'Wage_Bill')\n",
    "\n",
    "# final = employment.merge(wage, on=['Year', 'COMZONE', 'Occupation'], how='left')\n",
    "final = employment.merge(wb, on=['Year', 'COMZONE', 'Occupation'], how='left')\n",
    "# final.to_csv('master.csv', index=False)\n",
    "\n",
    "df_cpi = pd.read_csv('raw/CPI.csv')\n",
    "df_cpi['DATE'] = pd.to_datetime(df_cpi['DATE'])\n",
    "df_cpi['Year'] = df_cpi['DATE'].dt.year\n",
    "df_cpi['month'] = df_cpi['DATE'].dt.month\n",
    "df_cpi = df_cpi[df_cpi['month'] == 12]\n",
    "df_cpi = df_cpi.rename(columns={'CPIAUCSL': 'CPI'})\n",
    "df_cpi = df_cpi[['Year', 'CPI']]\n",
    "\n",
    "base_year = 1990\n",
    "\n",
    "final = final.merge(df_cpi, on='Year', how='left')\n",
    "final['Wage'] = final['Wage_Bill'] / final['Employed']\n",
    "final['Wage_Bill'] = (final['Wage_Bill'] / final['CPI']) * df_cpi[df_cpi['Year'] == base_year]['CPI'].values[0]\n",
    "final = final[['Year', 'COMZONE', 'NAME', 'Occupation', 'Employed', 'Wage', 'Wage_Bill', 'CPI']]\n",
    "\n",
    "final.to_csv('master.csv', index=False)\n",
    "\n",
    "# final = pd.read_csv('master.csv')\n",
    "\n",
    "# years = [1990, 2000, 2010, 2018]\n",
    "# final = final[final['Year'].isin(years)]\n",
    "# final.to_csv('master_filtered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_names_cw = pd.read_csv('raw/puma_fips.csv')\n",
    "df_names = pd.read_csv('raw/cz_mappings.csv')\n",
    "df_pop = pd.read_csv('raw/archive/cz_county.csv')\n",
    "df_puma_cz = pd.read_csv('raw/cw_puma2000_czone.csv', encoding='latin1')\n",
    "\n",
    "df_names_cw['puma2000'] = df_names_cw['STATEFP'] * 10000 + df_names_cw['PUMA5CE']\n",
    "df_names_cw['FIPS'] = df_names_cw['STATEFP'] * 1000 + df_names_cw['COUNTYFP']\n",
    "df_names_cw = df_names_cw.drop_duplicates(subset=['puma2000', 'FIPS'])\n",
    "df_names_cw = df_names_cw[['puma2000', 'FIPS']]\n",
    "\n",
    "df_names = df_names[['FIPS', 'County Name']]\n",
    "df_names_cw = df_names_cw.merge(df_names, on='FIPS', how='left')\n",
    "\n",
    "df_names_cw = df_names_cw.merge(df_pop[['FIPS', 'Labor Force']], on='FIPS', how='left')\n",
    "\n",
    "df_names_cw = df_names_cw.merge(df_puma_cz, on='puma2000', how='left')\n",
    "\n",
    "idx = df_names_cw.groupby(['czone'])['Labor Force'].idxmax()\n",
    "df_names_cw = df_names_cw.loc[idx].reset_index(drop=True)\n",
    "df_names_cw = df_names_cw[['czone', 'County Name']]\n",
    "\n",
    "# df_names_cw.to_csv('raw/cz_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_ranges(df):\n",
    "    expanded_rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        if '-' in index:\n",
    "            start, end = map(int, index.split('-'))\n",
    "            for i in range(start, end + 1):\n",
    "                expanded_rows.append((str(i), row['Name']))\n",
    "        else:\n",
    "            expanded_rows.append((index, row['Name']))\n",
    "    return pd.DataFrame(expanded_rows, columns=['Sector', 'Name']).set_index('Sector')\n",
    "\n",
    "naics_codes = pd.read_csv('raw/2022_NAICS_codes.csv')\n",
    "naics_codes = naics_codes[['Sector', 'Name']]\n",
    "naics_codes.dropna(inplace=True)\n",
    "naics_codes.set_index('Sector', inplace=True)\n",
    "naics_codes.loc['0'] = 'N/A'\n",
    "naics_codes.loc['99'] = 'Unemployed'\n",
    "naics_codes.loc['50'] = 'Transportation and Warehousing'\n",
    "naics_codes.loc['3M'] = 'Manufacturing'\n",
    "naics_codes = expand_ranges(naics_codes)\n",
    "\n",
    "sic_to_naics = pd.read_csv('raw/full_sic87_naics97.csv')\n",
    "sic_to_naics = sic_to_naics[['sic87', 'naics97']]\n",
    "sic_to_naics = sic_to_naics.drop_duplicates(subset=['sic87'])\n",
    "\n",
    "city_sec = pd.read_csv('raw/efsy_cbp_1980.csv')\n",
    "city_sec['naics'] = city_sec['naics'].map(sic_to_naics.set_index('sic87')['naics97'])\n",
    "city_sec['naics'] = city_sec['naics'].str[:2].replace('--', '0').astype(str)\n",
    "city_sec['fips'] = city_sec['fipstate'] * 1000 + city_sec['fipscty']\n",
    "city_sec = city_sec.groupby(['naics', 'fips']).agg({\n",
    "    'ub': 'sum',\n",
    "    'lb': 'sum',\n",
    "    'fipstate': 'first',\n",
    "    'fipscty': 'first',\n",
    "}).reset_index()\n",
    "city_sec['employment'] = (city_sec['ub'] + city_sec['lb']) / 2\n",
    "city_sec['naics'] = city_sec['naics'].map(naics_codes['Name'])\n",
    "# city_sec = city_sec.drop_duplicates(subset=['fips', 'naics'])\n",
    "# city_sec = city_sec.pivot(index='fips', columns='naics', values='employment')\n",
    "\n",
    "df_names_cw = pd.read_csv('raw/puma_fips.csv')\n",
    "df_names = pd.read_csv('raw/cz_mappings.csv')\n",
    "df_puma_cz = pd.read_csv('raw/cw_puma2000_czone.csv', encoding='latin1')\n",
    "df_cz_names = pd.read_csv('raw/cz_names.csv')\n",
    "\n",
    "df_names_cw['puma2000'] = df_names_cw['STATEFP'] * 10000 + df_names_cw['PUMA5CE']\n",
    "df_names_cw['FIPS'] = df_names_cw['STATEFP'] * 1000 + df_names_cw['COUNTYFP']\n",
    "df_names_cw = df_names_cw.drop_duplicates(subset=['puma2000', 'FIPS'])\n",
    "df_names_cw = df_names_cw[['puma2000', 'FIPS']]\n",
    "\n",
    "df_names = df_names[['FIPS', 'County Name']]\n",
    "df_names_cw = df_names_cw.merge(df_names, on='FIPS', how='left')\n",
    "\n",
    "df_names_cw = df_names_cw.merge(df_puma_cz, on='puma2000', how='left')\n",
    "df_names_cw = df_names_cw[['FIPS', 'czone']]\n",
    "df_names_cw = df_names_cw.drop_duplicates(subset=['FIPS'])\n",
    "\n",
    "city_sec = city_sec.merge(df_names_cw, left_on='fips', right_on='FIPS', how='left')\n",
    "city_sec['czone_name'] = city_sec['czone'].map(df_cz_names.set_index('czone')['County Name'])\n",
    "city_sec = city_sec.drop_duplicates(subset=['czone', 'naics'])\n",
    "city_sec = city_sec[['czone', 'czone_name', 'naics', 'employment']]\n",
    "city_sec.to_csv('processed/city_sec_employment_1980.csv', index=False)\n",
    "# city_sec = city_sec.pivot(index='czone', columns='naics', values='employment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpi = pd.read_csv('raw/CPI.csv')\n",
    "df_cpi['DATE'] = pd.to_datetime(df_cpi['DATE'])\n",
    "df_cpi['year'] = df_cpi['DATE'].dt.year\n",
    "df_cpi['month'] = df_cpi['DATE'].dt.month\n",
    "df_cpi = df_cpi[df_cpi['month'] == 12]\n",
    "df_cpi = df_cpi.rename(columns={'CPIAUCSL': 'CPI'})\n",
    "df_cpi = df_cpi[['year', 'CPI']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
